@[TOC](python下载百度文库文档)

# 背景
我想很多人跟我一的经历，想复制百度文库的内容却发现要开会员，天下苦百度文库久矣，本是广大网友存放文档的地方，结果各种下载券，会员不胜其烦，那么能不能用技术手段避开这一结界呢？ 简化到只需要输入文档地址，然后文档就乖乖的保存到自己电脑上呢？想想就很巴适，利用python爬虫技术确实可以做到这一点。

想要破解百度的门禁在实际操作层面也是一件比较麻烦的事情，但好在天无绝人之路，哪里有加密哪里就有解密，先说一说博主的需求，博主主要是写数学讲义的时候，想收集一些经典习题，然后自己讲解并编辑排版，感兴趣的朋友可以关注微信公众号“三行科创”，而网上很大一部分素材都集中在百度文库，博主希望技术能够做到，当输入文档的地址后，能够把文档里面的文字内容原封不动的复制出来，并且文档里面的配图素材也能一并弄下来，这样就相当于素材收集齐全。

```flow

st=>start: 请输入文档地址
op=>operation: 获取文档摘要（docid, title, doctype）
cond=>condition: text & image
e=>end: 结束

st->op
op->cond(yes)->e
    
```

# 思路
 - downloadWenku实现文档下载；
 - 调用fetch_text函数解析文档里文字内容，将文字内容统一格式写入word；
 - 调用 fetch_image函数获取文档里插图素材，将图片内容保存到同名文件夹下；
 
 
# 代码


# 改进方向
1，保存为10997-2003以后的docx格式;
   如果保存为doc格式，用2007以后的word软件打开会出现让你选择文档可读编码utf-8，这个最好在保存的同时处理掉；
2，将文档里面的图片有一部分可以显示，有一部分似乎不支持文件格式；

# 参考资料
1, https://my.oschina.net/u/4579171/blog/4344181

2, https://www.cnblogs.com/LQ6H/p/12940524.html

# 免责申明

爬虫技术仅供技术交流使用，不得作为商业用途。